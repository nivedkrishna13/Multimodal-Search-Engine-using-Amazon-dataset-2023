import os
import torch
import requests
import pandas as pd
import numpy as np
from PIL import Image
from tqdm import tqdm
from transformers import CLIPProcessor, CLIPModel
from io import BytesIO
import pyarrow.parquet as pq
from concurrent.futures import ThreadPoolExecutor

# ======================
# CONFIG
# ======================
DATA_PATH = "/kaggle/input/datasets/nivedkrishna13/amazon-clean-parquet-complete/amazon_clean.parquet"
OUTPUT_DIR = "embeddings"
BATCH_SIZE = 192        # Increased for P100
MAX_WORKERS = 32          # Parallel downloads
os.makedirs(OUTPUT_DIR, exist_ok=True)

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

# ======================
# LOAD CLIP
# ======================
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
model.eval()

# ======================
# IMAGE DOWNLOAD (Parallel)
# ======================
def download_image(url):
    try:
        response = requests.get(url, timeout=5)
        img = Image.open(BytesIO(response.content)).convert("RGB")
        return img
    except:
        return None

def download_batch(urls):
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        images = list(executor.map(download_image, urls))
    return images

# ======================
# PROCESS CHUNK
# ======================
def process_chunk(df_chunk, chunk_id):

    image_embeddings = []
    text_embeddings = []
    valid_ids = []

    for start in tqdm(range(0, len(df_chunk), BATCH_SIZE)):

        batch = df_chunk.iloc[start:start + BATCH_SIZE]

        urls = batch["imgUrl"].tolist()
        texts = batch["title"].tolist()
        ids = batch["asin"].tolist()

        images = download_batch(urls)

        # Filter failed downloads
        valid_data = [
            (img, txt, id_)
            for img, txt, id_ in zip(images, texts, ids)
            if img is not None
        ]

        if len(valid_data) == 0:
            continue

        images, texts, ids = zip(*valid_data)

        inputs = processor(
            text=list(texts),
            images=list(images),
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=77
        ).to(device)

        with torch.no_grad():
            with torch.cuda.amp.autocast():   # Mixed precision
                outputs = model(**inputs)

                img_emb = outputs.image_embeds
                txt_emb = outputs.text_embeds

                img_emb = img_emb / img_emb.norm(dim=-1, keepdim=True)
                txt_emb = txt_emb / txt_emb.norm(dim=-1, keepdim=True)

        image_embeddings.append(img_emb.cpu().numpy())
        text_embeddings.append(txt_emb.cpu().numpy())
        valid_ids.extend(ids)

        del inputs, outputs
        torch.cuda.empty_cache()

    if len(image_embeddings) == 0:
        return

    image_embeddings = np.vstack(image_embeddings)
    text_embeddings = np.vstack(text_embeddings)

    np.save(f"{OUTPUT_DIR}/image_emb_chunk_{chunk_id}.npy", image_embeddings)
    np.save(f"{OUTPUT_DIR}/text_emb_chunk_{chunk_id}.npy", text_embeddings)

    pd.Series(valid_ids).to_csv(
        f"{OUTPUT_DIR}/ids_chunk_{chunk_id}.csv",
        index=False
    )

    print(f"Saved chunk {chunk_id}")

# ======================
# MAIN
# ======================
def main():
    print("Reading dataset in row groups...")

    parquet_file = pq.ParquetFile(DATA_PATH)

    for i in range(parquet_file.num_row_groups):
        print(f"\nProcessing row group {i}")

        df_chunk = parquet_file.read_row_group(i).to_pandas()
        process_chunk(df_chunk, i)

if __name__ == "__main__":
    main()